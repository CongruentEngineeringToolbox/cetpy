"""
Parallel Case Runner
===========

This file defines a CET case runner, that extends the original one and allows
parallel processing on n cores.

NOTE: I am not familiar enough with cetpy and it's inner workings, so I 
implemented the class in a way, that doesn't require to dig too deeply into 
cetpys internal structure.
This is the reason, why the output `DataFrame` is generated by a function and 
not by a property (`compute_output_df` instead of `output_df`).
"""

from multiprocessing import Pool
from typing import Optional

import cetpy.CaseTools
import cetpy.Modules.SysML
import numpy as np
import pandas as pd


class ParallelCaseRunner(cetpy.CaseTools.CaseRunner):
    """Same as `CaseRunner`, but can perform calculations in n parallel
    processes.
    """

    def _serialize(self) -> dict:
        """Returns all arguments, needed to create a copy of original
        `CaseRunner` in a different process.

        Rationale
        ---------
        `CaseRunner` objects are not picklable due to decorators (idk what
        pythons problem with them is), so we cannot just pass the original
        object to other thread and make a copy there.
        Also we could just use the `self.__dict__` but
        `self.case_generator.__dict__` is not picklable either.
        """
        return {
            "_module": self.module,
            "_save_instances": self.save_instances,
            "_additional_module_kwargs": self.additional_module_kwargs,
            "_output_properties": self.output_properties,
            "_sub_method": self.case_generator.sub_method,
            "_case_df_postprocess_function": self.case_generator.case_df_postprocess_function,
            "_output_df_postprocess_function": self.output_df_postprocess_function,
            "_custom_evaluation_function": self.custom_evaluation_function,
            "_enable_default_evaluation": self.enable_default_evaluation,
            "_catch_errors": self.catch_errors,
        }

    @staticmethod
    def _compute_cases(cr_args: dict, cases: pd.DataFrame) -> pd.DataFrame:
        """The function, passed to pool workers. It has to be static, because
        python.

        Parameters
        ----------
        cr_args
            Dictionary, that contains all information, needed to create (almost)
            copies of original `CaseRunner`. Every worker has own `CaseRunner`,
            because these objects have internal state and thus can't be shared
            between processes.
        cases
            Pandas `DataFrame` with cases to compute in "direct" mode. The idea
            is to generate cases in original process, split them in equal parts
            and pass to worker processes. This is not exactly efficient, but
            splitting ranges and generating cases in each process would result
            in gaps in design space (as far as I understand).
        """
        cr = cetpy.CaseTools.CaseRunner(
            cr_args["_module"],
            cases,
            save_instances=cr_args["_save_instances"],
            catch_errors=cr_args["_catch_errors"],
            additional_module_kwargs=cr_args["_additional_module_kwargs"],
            output_properties=cr_args["_output_properties"],
            method="direct",
            sub_method=cr_args["_sub_method"],
            n_cases=len(cases),
            case_df_postprocess_function=cr_args["_case_df_postprocess_function"],
            output_df_postprocess_function=cr_args["_output_df_postprocess_function"],
            custom_evaluation_function=cr_args["_custom_evaluation_function"],
            enable_default_evaluation=cr_args["_enable_default_evaluation"],
        )
        return cr.output_df

    def compute_output_df(self, n_cores: Optional[int] = 1) -> pd.DataFrame:
        """Return completed run of cases with input followed by output
        values.

        Parameters
        ----------
        n_cores: optional, default = 1
            Number of processes to create for calculations. It should not exceed
            the number of physical cores on you CPU (you can do it, but it won't
            speed anything up). This is also the number of parts, that the
            generated cases are split into.
        """
        if self._output_df is None:
            # Initialize output `DataFframe` from input `DataFrame` and add
            # columns for solver progress, any occurring error diagnostic,
            # and performance timing.
            self._output_df = self.input_df.copy()
            cols = [
                "solved",
                "errored",
                "error_class",
                "error_message",
                "error_location",
            ]
            self._output_df.loc[:, cols] = False
            self._output_df.loc[:, "code_time"] = np.nan

        # TODO: make a better solution than this. I don't know enough about
        # internal structure of cetpy to do it.
        if not self.case_solver.solved_calculating and not self.case_solver.hold:
            dfs = np.array_split(self.case_generator.case_df, n_cores)
            # `CaseRunner` objects are not picklable, so we pass arguments to
            # other processes to create own CaseRunners. It is necessary,
            # because the objects have internal state, which cannot be shared
            # safely over multiple threads
            args = [(self._serialize(), d) for d in dfs]
            with Pool(n_cores) as pool:
                evals = pool.starmap(ParallelCaseRunner._compute_cases, args)
                result = pd.concat(evals)
            self._output_df = result
        return self._output_df
